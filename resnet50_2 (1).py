# -*- coding: utf-8 -*-
"""resnet50-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dqBHmrZN7xBSIHL_yyTWw_s91f9AQeQU
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
sns.set()
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from skimage.transform import resize
import tensorflow as tf
from tensorflow import keras
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import *
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.applications.resnet50 import ResNet50

import os

from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
import tensorflow as tf

directory_path = "/content/drive/MyDrive/vishal/Pomegranate (P9)"

# Get the list of items within the directory
dir_contents = os.listdir(directory_path)
dir_contents

folders = [os.path.join(directory_path, item) for item in dir_contents if os.path.isdir(os.path.join(directory_path, item))]
folders

out_d="/content/drive/MyDrive/vishal/Pomegranate (P9)"
categary= ['diseased', 'healthy']

import os

train_dir= os.path.join(out_d,"train")
test_dir= os.path.join(out_d,"test")
os.makedirs(train_dir,exist_ok=True)
os.makedirs(test_dir,exist_ok=True)

import shutil
from sklearn.model_selection import train_test_split

# for cat in categary:
#   cat_path= os.path.join(directory_path,cat)
#   images= os.listdir(cat_path)

#   train_img, test_img = train_test_split(images,test_size=0.2,random_state=32)
#   train_path= os.path.join(train_dir, cat)
#   test_path = os.path. join (test_dir,cat)
#   os.makedirs(train_path,exist_ok=True)
#   os.makedirs(test_path,exist_ok=True)

#   for i in train_img:
#     shutil.copy(os.path.join(cat_path,i),os.path.join(train_path,i))
#   print("train")

#   for i in test_img:
#     shutil.copy(os.path.join(cat_path,i),os.path.join(test_path,i))
#   print("test")
# print("splite")

for cat in categary:
    train_folder = os.path.join(train_dir, cat)
    test_folder = os.path.join(test_dir, cat)

    train_count = len(os.listdir(train_folder))
    test_count = len(os.listdir(test_folder))

    print(f"Total training images in '{cat}': {train_count}")
    print(f"Total testing images in '{cat}': {test_count}")

print("Split complete")

len("train")

# import os
# from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img
# import numpy as np
# from PIL import Image

# # Paths to your training data
# train_dir = r"/content/drive/MyDrive/vishal/Pomegranate (P9)/train"
# save_augmented_dir = r"/content/drive/MyDrive/vishal/Pomegranate (P9)/augmented"

# # Ensure the output directory exists
# os.makedirs(save_augmented_dir, exist_ok=True)

# # Function to apply specific augmentations and save images
# def augment_and_save_images(class_folder, save_class_dir):
#     # Ensure the save directory for the class exists
#     os.makedirs(save_class_dir, exist_ok=True)

#     # Get all images in the class folder
#     image_files = [f for f in os.listdir(class_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

#     for image_file in image_files:
#         # Load the image
#         img_path = os.path.join(class_folder, image_file)
#         img = load_img(img_path)  # Load the image as a PIL image
#         img_array = img_to_array(img)  # Convert to numpy array

#         # Augmentation 1: Flip horizontally
#         flipped_img = np.fliplr(img_array)
#         flipped_img = array_to_img(flipped_img)
#         flipped_filename = f"{os.path.splitext(image_file)[0]}_flipped.jpg"
#         flipped_img.save(os.path.join(save_class_dir, flipped_filename))

#         # Augmentation 2: Rotate +15 degrees
#         rotated_plus_15 = img.rotate(15, resample=Image.BICUBIC, fillcolor=(0, 0, 0))
#         rotated_plus_15_filename = f"{os.path.splitext(image_file)[0]}_rotated_plus_15.jpg"
#         rotated_plus_15.save(os.path.join(save_class_dir, rotated_plus_15_filename))


# # Process each class folder
# for class_name in os.listdir(train_dir):
#     class_folder = os.path.join(train_dir, class_name)
#     if os.path.isdir(class_folder):
#         save_class_dir = os.path.join(save_augmented_dir, class_name)
#         augment_and_save_images(class_folder, save_class_dir)

# print(f"Augmented images saved in: {save_augmented_dir}")

# Paths to your dataset
train_dir = '/content/drive/MyDrive/vishal/Pomegranate (P9)/train'
test_dir = '/content/drive/MyDrive/vishal/Pomegranate (P9)/test'

# Split the training data into training and validation sets
train_classes = os.listdir(train_dir)
val_dir = '/content/drive/MyDrive/vishal/Pomegranate (P9)/val'
os.makedirs(val_dir, exist_ok=True)

for class_name in train_classes:
    class_path = os.path.join(train_dir, class_name)
    val_class_path = os.path.join(val_dir, class_name)
    os.makedirs(val_class_path, exist_ok=True)

    # List all images in the class folder
    images = os.listdir(class_path)

    # Split images into training and validation
    train_images, val_images = train_test_split(images, test_size=0.1, random_state=42)

    # Move validation images to the validation folder
    for val_image in val_images:
        os.rename(os.path.join(class_path, val_image), os.path.join(val_class_path, val_image))

# Initialize the base model with pre-trained weights, excluding the top layers
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers to prevent them from being updated during initial training
for layer in base_model.layers:
    layer.trainable = False

# Add custom layers on top of the base model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)  # Binary classification

# Define the complete model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Data augmentation and preprocessing
train_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.resnet50.preprocess_input
)

# Data generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Callbacks for saving the best model and reducing learning rate on plateau
checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=1)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // val_generator.batch_size,
    epochs=10,
    callbacks=[checkpoint, reduce_lr]
)

# Evaluate the model on the test set
test_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.resnet50.preprocess_input
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test Accuracy: {test_accuracy:.2f}')





import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Get the true labels and predicted labels for the test data
y_true = []
y_pred = []

# Loop through the test data
for i in range(len(test_generator)):
    x_batch, y_batch = test_generator[i]
    y_true.extend(y_batch)

    # Make predictions
    predictions = model.predict(x_batch)
    y_pred.extend(np.round(predictions).flatten())

# Convert lists to numpy arrays
y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plotting the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

import matplotlib.pyplot as plt

# Extract training and validation accuracy and loss from the history object
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Number of epochs
epochs = range(1, len(train_accuracy) + 1)

# Plot training and validation accuracy
plt.figure(figsize=(12, 6))
plt.plot(epochs, train_accuracy, label='Training Accuracy')
plt.plot(epochs, val_accuracy, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()
plt.show()

# Plot training and validation loss
plt.figure(figsize=(12, 6))
plt.plot(epochs, train_loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

