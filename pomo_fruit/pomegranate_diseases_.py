# -*- coding: utf-8 -*-
"""Pomegranate Diseases .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ArDOnmlMia3cRQjyUj__81W9mJBtwzwo

libraries
"""

import os
import math
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import random as python_random
import tensorflow as tf
import seaborn as sns
import math
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
from tensorflow.keras.callbacks import ModelCheckpoint
from  tensorflow.keras.callbacks import EarlyStopping
from keras import backend as K
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import random
import shutil

from google.colab import drive
drive.mount('/content/drive')

"""unzip"""

import zipfile
import os

# Path to the ZIP file
zip_file_path = "/content/drive/MyDrive/vishal/a.zip"

# Destination folder for unzipped files
destination_path = "/content/drive/MyDrive/vishal/unzipped_files"

# Create the destination folder if it doesn't exist
os.makedirs(destination_path, exist_ok=True)

# Unzipping the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(destination_path)

print(f"Files extracted to: {destination_path}")



"""model"""

np.random.seed(42)
tf.random.set_seed(42)

HEIGHT=224
WIDTH=224
BATCH_SIZE=32

# rescale pixel value [0,1]
train_datagen = ImageDataGenerator(rescale = 1./255)
test_datagen = ImageDataGenerator(rescale = 1./255)

# Train and test directory paths
train_dir = r"/content/drive/MyDrive/vishal/unzipped_files/a/train"
test_dir = r"/content/drive/MyDrive/vishal/unzipped_files/a/test"

# Data augmentation and normalization for training
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values to [0, 1]
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Normalization for testing
test_datagen = ImageDataGenerator(rescale=1./255)

# Create generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(HEIGHT, WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='sparse',
    shuffle=True,
    classes={'Alternaria': 0, 'Anthracnose': 1, 'Bacterial_Blight': 2, 'Cercospora': 3, 'Healthy': 4}
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(HEIGHT, WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='sparse',
    shuffle=False,
    classes={'Alternaria': 0, 'Anthracnose': 1, 'Bacterial_Blight': 2, 'Cercospora': 3, 'Healthy': 4}
)

total_image = np.concatenate([train_generator.labels,test_generator.labels])

print('Alternaria: ',len(np.where(total_image==0)[0]))
print('Anthracnose: ',len(np.where(total_image==1)[0]))
print('Bacterial_Blight: ',len(np.where(total_image==2)[0]))
print('Cercospora: ',len(np.where(total_image==3)[0]))
print('Healthy: ',len(np.where(total_image==4)[0]))

train_generator.labels.shape

np.unique(train_generator.labels)

images, labels = next(train_generator)

labels.shape

def plot_images(images_arr, labels_arr, class_indices):
    fig, axes = plt.subplots(1, len(images_arr), figsize=(20,20))
    axes = axes.flatten()
    for img, lbl, ax in zip(images_arr, labels_arr, axes):
        ax.imshow(img)
        ax.axis('off')
        label = list(class_indices.keys())[list(class_indices.values()).index(int(lbl))]
        ax.set_title(label)
    plt.tight_layout()
    plt.show()

labels[:5]

# Display first 5 images from the batch
plot_images(images[:5], labels[:5], train_generator.class_indices)

tf.keras.backend.clear_session()

# Ensure train_generator is properly initialized
num_classes = len(train_generator.class_indices)  # Dynamically calculate the number of classes
print("Number of classes:", num_classes)

# One-hot encode labels
from tensorflow.keras.utils import to_categorical

train_labels_one_hot = to_categorical(train_generator.labels, num_classes=num_classes)
test_labels_one_hot = to_categorical(test_generator.labels, num_classes=num_classes)

# Loading VGG16 Model with Pre-trained Weights - without final (top) later as we will customize it
base_model = VGG16(weights='imagenet',
                   include_top=False,
                   input_shape=(HEIGHT, WIDTH, 3))



for layer in base_model.layers:
    layer.trainable = False

num_classes = len(train_generator.class_indices)
print('Number of classes:', num_classes)

model = Sequential()
model.add(base_model)
model.add(GlobalAveragePooling2D())
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',  # For integer-encoded labels
    metrics=['accuracy']  # Only accuracy
)
checkpoint = tf.keras.callbacks.ModelCheckpoint(
    filepath='vgg16_best_weights.weights.h5',  # Save weights only
    monitor='val_accuracy',
    verbose=1,
    mode='max',
    save_best_only=True,
    save_weights_only=True
)

early = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    mode="min",
    restore_best_weights=True,
    patience=5
)

callbacks_list = [checkpoint, early]
# Fit the model
history = model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator,
    callbacks=callbacks_list,
    verbose=True,
    shuffle=True
)

model.save('vgg16_complete_model1.h5')

"""plots"""

def plot_learning_curve(history, metrics):
    acc = history.history[metrics]
    val_acc = history.history[f'val_{metrics}']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(acc))

    plt.figure(figsize=(5,3))
    plt.plot(epochs, acc, label=f'training {metrics}')
    plt.plot(epochs, val_acc, label=f'validation {metrics}')
    plt.grid()
    plt.xlabel('Epochs')
    plt.ylabel(metrics)
    plt.legend()

    plt.figure(figsize=(5,3))
    plt.plot(epochs, loss, label='training loss')
    plt.plot(epochs, val_loss, label='validation loss')
    plt.grid()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.show()

plot_learning_curve(history, metrics='accuracy')

train_result = model.evaluate(train_generator)
test_result = model.evaluate(test_generator)

print(f"Train Loss: {np.round(train_result[0], 4)}")
print(f"Test Loss: {np.round(test_result[0], 4)}")
print(f"Train Accuracy: {np.round(train_result[1], 3)}")
print(f"Test Accuracy: {np.round(test_result[1], 3)}")

y_pred_probs = model.predict(test_generator)
print(y_pred_probs.shape)

y_true = test_generator.classes
y_true

classes_names = list(test_generator.class_indices.keys())

# Convert predicted probabilities to class labels
y_pred = np.argmax(y_pred_probs, axis=1)
# Calculate confusion matrix
confusion = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", confusion)
# Calculate perfect confusion matrix
p_confusion = confusion_matrix(y_true, y_true)
print("Perfect Confusion Matrix:\n", p_confusion)
# Calculate precision, recall, and f1-score
report = classification_report(y_true, y_pred, target_names=classes_names)
print("\nClassification Report:\n", report)

plt.figure(figsize=(5, 5))
hmap = sns.heatmap(confusion, annot=True, vmin=0,
                 fmt='g', cmap='Blues', cbar=False,
                 xticklabels=classes_names,
                 yticklabels=classes_names)

hmap.set(xlabel='Predicted Labels')
hmap.set(ylabel='True Labels')
plt.show()

#Extract wrong classification index
wrong_pred = np.where(y_pred!=y_true)[0]
print(f'Total of {len(wrong_pred)} missclassified images')
print('Missclassified images index: ',wrong_pred)

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

# Binarize labels for multiclass ROC
y_true_binarized = label_binarize(y_true, classes=list(range(num_classes)))

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot ROC curve
plt.figure(figsize=(8, 6))
for i in range(num_classes):
    plt.plot(fpr[i], tpr[i], label=f'Class {classes_names[i]} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

from sklearn.metrics import precision_recall_curve, average_precision_score

# Compute Precision-Recall curve and average precision for each class
precision = dict()
recall = dict()
avg_precision = dict()
for i in range(num_classes):
    precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], y_pred_probs[:, i])
    avg_precision[i] = average_precision_score(y_true_binarized[:, i], y_pred_probs[:, i])

# Plot PR curve
plt.figure(figsize=(8, 6))
for i in range(num_classes):
    plt.plot(recall[i], precision[i], label=f'Class {classes_names[i]} (AP = {avg_precision[i]:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='lower left')
plt.grid()
plt.show()



class_accuracy = np.diag(confusion) / np.sum(confusion, axis=1)

plt.figure(figsize=(8, 6))
plt.bar(classes_names, class_accuracy, color='skyblue')
plt.ylim(0, 1)
plt.ylabel('Accuracy')
plt.title('Class-wise Accuracy')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

def display_misclassified_images(generator, y_true, y_pred, wrong_pred_indices, num_images=5):
    plt.figure(figsize=(15, 10))
    for i, idx in enumerate(wrong_pred_indices[:num_images]):
        img, _ = generator[idx]
        plt.subplot(1, num_images, i + 1)
        plt.imshow(img[0])  # Assuming batch size = 1
        plt.title(f'True: {classes_names[y_true[idx]]}\nPred: {classes_names[y_pred[idx]]}')
        plt.axis('off')
    plt.show()

display_misclassified_images(test_generator, y_true, y_pred, wrong_pred, num_images=5)



